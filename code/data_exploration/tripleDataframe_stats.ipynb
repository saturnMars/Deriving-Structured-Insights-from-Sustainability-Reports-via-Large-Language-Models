{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from json import load\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_triples = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clustered_triples:\n",
    "    file_names = ['triples_wizardLM_filtering.json']\n",
    "    folder_path = path.join('..', 'outputs', 'genSRL', 'clustered_t80')\n",
    "else:\n",
    "    file_names = ['triples_wizardLM_filtering_setA.json', 'triples_wizardLM_filtering_setB.json', 'triples_wizardLM_filtering_setC.json', 'triples_wizardLM_filtering_setD.json', 'triples_wizardLM_filtering_setE.json']\n",
    "    folder_path = path.join('..', 'outputs', 'genSRL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPANIES: 128 \n",
      "\n",
      "1) 3M Corporation\n",
      "2) 3i Group plc\n",
      "3) Activision Blizzard Inc\n",
      "4) Adecco Group AG\n",
      "5) Adidas AG\n",
      "6) Air Canada\n",
      "7) Air Liquide SA\n",
      "8) Airbus SE\n",
      "9) Alcon Inc\n",
      "10) Alibaba Group Holding Limited\n",
      "11) Alphabet Inc\n",
      "12) Aluminum Corporation of China Limited\n",
      "13) Amazoncom Inc\n",
      "14) American Electric Power Company Inc\n",
      "15) Amplifon\n",
      "16) Apple Inc\n",
      "17) ArcelorMittal SA\n",
      "18) Assicurazioni Generali SpA\n",
      "19) AstraZeneca PLC\n",
      "20) AstraZeneca plc\n",
      "21) BPER Banca SpA\n",
      "22) Baidu Inc\n",
      "23) Banco Santander SA\n",
      "24) Bank of America Corp BofA\n",
      "25) Bayer AG\n",
      "26) British American Tobacco PLC\n",
      "27) British American Tobacco plc\n",
      "28) British Land Co PLC The\n",
      "29) Broadcom Inc\n",
      "30) Builders FirstSource Inc\n",
      "31) CF Industries Holdings Inc\n",
      "32) Campbell Soup Company\n",
      "33) Canadian Pacific Railway Limited\n",
      "34) Canon Inc\n",
      "35) CarMax Inc\n",
      "36) China Evergrande Group\n",
      "37) China Petroleum Chemical Corporation\n",
      "38) Cisco Systems Inc\n",
      "39) Coca Cola\n",
      "40) Commonwealth Bank of Australia\n",
      "41) Croda International plc\n",
      "42) Daikin Industries Ltd\n",
      "43) Delta Air Lines Inc\n",
      "44) Deutsche Bank AG\n",
      "45) Deutsche Lufthansa AG\n",
      "46) Deutsche Wohnen\n",
      "47) DuPont\n",
      "48) ENI SpA\n",
      "49) Edison International\n",
      "50) Enel SpA\n",
      "51) FedEx Corporation\n",
      "52) First Republic Bank CA\n",
      "53) Fox Corporation\n",
      "54) Franklin Electric Co Inc\n",
      "55) Geely Automobile Holdings Ltd\n",
      "56) General Motors Co GM\n",
      "57) GlobalFoundries\n",
      "58) Goldman Sachs Group Inc The\n",
      "59) Home Depot Inc The\n",
      "60) Humana Inc\n",
      "61) Hyundai Motor Co\n",
      "62) Imperial Oil Ltd\n",
      "63) Intel Corp\n",
      "64) Intuitive Surgical Inc\n",
      "65) Iveco Group NV\n",
      "66) Johnson Johnson\n",
      "67) Kia Corp\n",
      "68) Korean Air Lines Co Ltd\n",
      "69) Kraft Heinz Co The\n",
      "70) LG Display Co Ltd\n",
      "71) Leonardo SpA\n",
      "72) Lockheed Martin Corp\n",
      "73) Mastercard Inc\n",
      "74) Meta Platforms Inc\n",
      "75) Microsoft Corporation\n",
      "76) Moderna Inc\n",
      "77) Monster Beverage Corp\n",
      "78) NVIDIA Corp\n",
      "79) National Grid PLC\n",
      "80) Nestle SA\n",
      "81) Netflix Inc\n",
      "82) Novo Nordisk A S\n",
      "83) Oracle Corporation\n",
      "84) PPG Industries\n",
      "85) Paramount Resources Ltd\n",
      "86) Park Hotels Resorts Inc\n",
      "87) PepsiCo Inc\n",
      "88) Pepsico Inc\n",
      "89) Petroleo Brasileiro SA Petrobras\n",
      "90) Philip Morris International\n",
      "91) Poste Italiane\n",
      "92) Prologis Inc\n",
      "93) Royal Bank of Canada\n",
      "94) Royal Dutch Shell PLC\n",
      "95) STMicroelectronics\n",
      "96) Saipem SpA\n",
      "97) Samsung Electronics Co Ltd\n",
      "98) Saudi Aramco\n",
      "99) Simon Property Group Inc\n",
      "100) SkyWest Inc\n",
      "101) Sligro Food Group NV\n",
      "102) Snam SpA\n",
      "103) Sony Corporation\n",
      "104) Sun Communities\n",
      "105) Swisscom AG\n",
      "106) Telecom Italia SpA\n",
      "107) Tesco PLC\n",
      "108) Tesla Inc\n",
      "109) Texas Instruments Inc\n",
      "110) Tokyo Gas Co Ltd\n",
      "111) Toshiba Corp\n",
      "112) TotalEnergies\n",
      "113) Toyota Motor Corp\n",
      "114) Uber Technologies Inc\n",
      "115) UniCredit SpA\n",
      "116) Uniper SE\n",
      "117) United States Steel Corp\n",
      "118) VMware Inc\n",
      "119) Vertex Pharmaceuticals Inc\n",
      "120) Virgin Atlantic Ltd\n",
      "121) Visa Inc\n",
      "122) Vodafone Group plc\n",
      "123) WESCO International Inc\n",
      "124) Walmart Inc\n",
      "125) Walt Disney Co\n",
      "126) Washington Real Estate Investment Trust\n",
      "127) Yamana Gold Inc\n",
      "128) adidas AG\n"
     ]
    }
   ],
   "source": [
    "triple_data = dict()\n",
    "for file_name in file_names:\n",
    "    file_path = path.join(folder_path, file_name)\n",
    "    with open(file_path) as fp:\n",
    "        triple_data.update(load(fp))\n",
    "print(\"COMPANIES:\", len(triple_data.keys()), '\\n')\n",
    "print('\\n'.join([ f'{idk + 1}) {companyName}'for idk, companyName in enumerate(sorted(triple_data.keys()))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>category</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "      <th>original</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3M Corporation</td>\n",
       "      <td>Access to Basic Services</td>\n",
       "      <td>Availability of education</td>\n",
       "      <td>In areas including medical, dental, orthodonti...</td>\n",
       "      <td>Education is available in areas including medi...</td>\n",
       "      <td>ACCESS TO BASIC SERVICES: availability of educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3M Corporation</td>\n",
       "      <td>Access to Basic Services</td>\n",
       "      <td>Challenges related to</td>\n",
       "      <td>Land ownership and engagement in forestry</td>\n",
       "      <td>African Americans in the rural south have long...</td>\n",
       "      <td>ACCESS TO BASIC SERVICES: challenges related to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3M Corporation</td>\n",
       "      <td>Access to Healthcare</td>\n",
       "      <td>Availability of education</td>\n",
       "      <td>A broad range of platforms to help assure acce...</td>\n",
       "      <td>As digitization plays an increasingly importan...</td>\n",
       "      <td>ACCESS TO HEALTHCARE: availability of education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3M Corporation</td>\n",
       "      <td>Accessibility</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>Accessibility with the understanding that our ...</td>\n",
       "      <td>We are approaching accessibility with the unde...</td>\n",
       "      <td>ACCESSIBILITY: approaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3M Corporation</td>\n",
       "      <td>Accessibility</td>\n",
       "      <td>Design for</td>\n",
       "      <td>Easily printable website pages</td>\n",
       "      <td>The website pages are designed to be easily pr...</td>\n",
       "      <td>ACCESSIBILITY: design for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49792</th>\n",
       "      <td>adidas AG</td>\n",
       "      <td>Supply Chain</td>\n",
       "      <td>Description of</td>\n",
       "      <td>The greatest labor and environmental, health, ...</td>\n",
       "      <td>Description of the greatest (1) labor and (2) ...</td>\n",
       "      <td>SUPPLY CHAIN: description of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49793</th>\n",
       "      <td>adidas AG</td>\n",
       "      <td>Supply Chain</td>\n",
       "      <td>Number of</td>\n",
       "      <td>Tier 1 suppliers and suppliers beyond Tier 1</td>\n",
       "      <td>Number of (1) Tier 1 suppliers and (2) supplie...</td>\n",
       "      <td>SUPPLY CHAIN: number of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49794</th>\n",
       "      <td>adidas AG</td>\n",
       "      <td>Supply Chain</td>\n",
       "      <td>Working with</td>\n",
       "      <td>520 independent supplier facilities (Tier 1)</td>\n",
       "      <td>At the end of 2020 adidas worked with 520 inde...</td>\n",
       "      <td>SUPPLY CHAIN: working with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795</th>\n",
       "      <td>adidas AG</td>\n",
       "      <td>Product Sustainability</td>\n",
       "      <td>Standardization of</td>\n",
       "      <td>SASB's standards for sustainability disclosure</td>\n",
       "      <td>1. The Sustainability Accounting Standards Boa...</td>\n",
       "      <td>PRODUCT SUSTAINABILITY: standardization of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49796</th>\n",
       "      <td>adidas AG</td>\n",
       "      <td>Waste</td>\n",
       "      <td>Setting a goal to</td>\n",
       "      <td>80% of applicable suppliers to achieve a ‘ZDHC...</td>\n",
       "      <td>We aim for 80% of applicable suppliers that op...</td>\n",
       "      <td>WASTE: setting a goal to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49797 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                  category                  predicate  \\\n",
       "0      3M Corporation  Access to Basic Services  Availability of education   \n",
       "1      3M Corporation  Access to Basic Services      Challenges related to   \n",
       "2      3M Corporation      Access to Healthcare  Availability of education   \n",
       "3      3M Corporation             Accessibility                Approaching   \n",
       "4      3M Corporation             Accessibility                 Design for   \n",
       "...               ...                       ...                        ...   \n",
       "49792       adidas AG              Supply Chain             Description of   \n",
       "49793       adidas AG              Supply Chain                  Number of   \n",
       "49794       adidas AG              Supply Chain               Working with   \n",
       "49795       adidas AG    Product Sustainability         Standardization of   \n",
       "49796       adidas AG                     Waste          Setting a goal to   \n",
       "\n",
       "                                                  object  \\\n",
       "0      In areas including medical, dental, orthodonti...   \n",
       "1              Land ownership and engagement in forestry   \n",
       "2      A broad range of platforms to help assure acce...   \n",
       "3      Accessibility with the understanding that our ...   \n",
       "4                         Easily printable website pages   \n",
       "...                                                  ...   \n",
       "49792  The greatest labor and environmental, health, ...   \n",
       "49793       Tier 1 suppliers and suppliers beyond Tier 1   \n",
       "49794       520 independent supplier facilities (Tier 1)   \n",
       "49795     SASB's standards for sustainability disclosure   \n",
       "49796  80% of applicable suppliers to achieve a ‘ZDHC...   \n",
       "\n",
       "                                                original  \\\n",
       "0      Education is available in areas including medi...   \n",
       "1      African Americans in the rural south have long...   \n",
       "2      As digitization plays an increasingly importan...   \n",
       "3      We are approaching accessibility with the unde...   \n",
       "4      The website pages are designed to be easily pr...   \n",
       "...                                                  ...   \n",
       "49792  Description of the greatest (1) labor and (2) ...   \n",
       "49793  Number of (1) Tier 1 suppliers and (2) supplie...   \n",
       "49794  At the end of 2020 adidas worked with 520 inde...   \n",
       "49795  1. The Sustainability Accounting Standards Boa...   \n",
       "49796  We aim for 80% of applicable suppliers that op...   \n",
       "\n",
       "                                                  action  \n",
       "0      ACCESS TO BASIC SERVICES: availability of educ...  \n",
       "1        ACCESS TO BASIC SERVICES: challenges related to  \n",
       "2        ACCESS TO HEALTHCARE: availability of education  \n",
       "3                             ACCESSIBILITY: approaching  \n",
       "4                              ACCESSIBILITY: design for  \n",
       "...                                                  ...  \n",
       "49792                       SUPPLY CHAIN: description of  \n",
       "49793                            SUPPLY CHAIN: number of  \n",
       "49794                         SUPPLY CHAIN: working with  \n",
       "49795         PRODUCT SUSTAINABILITY: standardization of  \n",
       "49796                           WASTE: setting a goal to  \n",
       "\n",
       "[49797 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data = []\n",
    "for companyName, triples in triple_data.items():\n",
    "    for triple in triples:\n",
    "        raw_data.append({\n",
    "            'company': companyName,\n",
    "            'category': triple['esg_category'],\n",
    "            'predicate': triple['predicate'],\n",
    "            'object': triple['object'],\n",
    "            'original': triple['properties']['original_sentence']\n",
    "        })\n",
    "df = pd.DataFrame(raw_data)\n",
    "df['action'] = df['category'].str.upper() + ': ' + df['predicate'].str.lower() #+ ' ' + df['object'].str.lower() \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>������������������������������������� ��������...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>�To take a truly holistic and proactive perspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>�Identified further areas/assets where a green...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>� ��������������������������������������������...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>� In addition to the tried and tested pandemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49792</th>\n",
       "      <td>\"With the green loan from UniCredit HypoVerein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49793</th>\n",
       "      <td>\"To effect change we have to redouble our effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49794</th>\n",
       "      <td>\"GHG Emissions Actual and Projected (MMT CO2e)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795</th>\n",
       "      <td>\"Fresh water\" includes water sourced from fres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49796</th>\n",
       "      <td>\"EPEC\" platform gives full play to the Company...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49797 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                original\n",
       "0      ������������������������������������� ��������...\n",
       "1      �To take a truly holistic and proactive perspe...\n",
       "2      �Identified further areas/assets where a green...\n",
       "3      � ��������������������������������������������...\n",
       "4      � In addition to the tried and tested pandemic...\n",
       "...                                                  ...\n",
       "49792  \"With the green loan from UniCredit HypoVerein...\n",
       "49793  \"To effect change we have to redouble our effo...\n",
       "49794  \"GHG Emissions Actual and Projected (MMT CO2e)...\n",
       "49795  \"Fresh water\" includes water sourced from fres...\n",
       "49796  \"EPEC\" platform gives full play to the Company...\n",
       "\n",
       "[49797 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original'].sort_values(ascending=False).reset_index(drop=True).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,item in df.sample(5).iterrows():\n",
    "    display(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the company info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info = pd.read_excel(path.join('..', 'data', 'companySectors_auto.xlsx'), index_col = 0)\n",
    "company_info = company_info.loc[df['company'].unique(), :] #[item.lower() for item in items]\n",
    "company_info['tmp'] = company_info.index.str.lower()\n",
    "company_info = company_info.drop_duplicates(subset = ['tmp']).drop(columns = ['tmp'])\n",
    "display(company_info)\n",
    "\n",
    "# Group by sector\n",
    "companyBySector = company_info.copy()\n",
    "companyBySector['Companies'] = companyBySector.index\n",
    "companyBySector = companyBySector[['Companies','Sector']].groupby('Sector').agg(Counter)\n",
    "companyBySector.insert(loc = 0, column = 'Count', value = companyBySector['Companies'].map(Counter.total))\n",
    "companyBySector['Companies'] = companyBySector['Companies'].map(lambda counter: ', '.join(sorted(counter.keys())))\n",
    "companyBySector = companyBySector.sort_values(by = 'Count', ascending = False)\n",
    "display(companyBySector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(path.join('..', 'data', 'selectedCompanies.xlsx'), ) as writer:\n",
    "    company_info[['yahooName','Sector', 'Industry', 'Ticker']].to_excel(writer, sheet_name='Companies')\n",
    "    companyBySector.to_excel(writer, sheet_name = 'Sectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the main dataframe with the company info\n",
    "merged_df = df.merge(company_info, left_on='company', right_index=True)\n",
    "\n",
    "# Compute the number of actions per company\n",
    "numCompanyActions = df[['company', 'action']].groupby('company').count().rename(columns = {'action':'actions'})\n",
    "numActionsBySector = merged_df[['Sector', 'action']].groupby('Sector').count().rename(columns = {'action':'actions'})\n",
    "\n",
    "node_counters = dict()\n",
    "sort_dict = lambda counter: dict(sorted(counter.items(), key=lambda dict_item: (dict_item[1], dict_item[0]), reverse = True))\n",
    "for col in ['category', 'action']:\n",
    "    \n",
    "    print('-' * 50, col, '-' * 50, '\\n')\n",
    "    \n",
    "    # Count the values\n",
    "    counter_df = merged_df[[col, 'company', 'Sector']].groupby(by = col).agg(Counter)\n",
    "    counter_df['company'] = counter_df['company'].map(sort_dict)\n",
    "    counter_df['Sector'] = counter_df['Sector'].map(sort_dict)\n",
    "    \n",
    "    # NEW COLUMN 0: item counter\n",
    "    counter_df.insert(loc = 0, column = 'count', value = (counter_df['company'].map(Counter.total) / merged_df.index.size).round(3))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------- COMPANIES ------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # NEW COLUMN 1A: [COMPANY] company cardinality\n",
    "    counter_df['company cardinality'] = counter_df['company'].map(lambda companyDict: np.round(len(companyDict.values()) / company_info.index.size, 2)) \n",
    "    \n",
    "    # NEW COLUMN 1B: [COMPANY] action per company (%)\n",
    "    counter_df['action per company (%)'] = counter_df['company'].map(\n",
    "        lambda dict_counter: dict(sorted([(company, round(action_counter / numCompanyActions.loc[company, 'actions'], 2)) for company, action_counter in dict_counter.items()], \n",
    "                                    key = lambda x: (x[1], x[0]), reverse = True)))\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------- SECTOR ---------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # NEW COLUMN 2A: Company sector coverage (%)\n",
    "    counter_df['company sector coverage (%)'] = counter_df['company'].map(lambda counter: Counter([company_info.loc[company, 'Sector'] for company in counter.keys()]))\n",
    "    counter_df['company sector coverage (%)'] = counter_df['company sector coverage (%)'].map(\n",
    "        lambda counter: dict(sorted([(sector, round(counter / companyBySector.loc[sector, 'Count'], 4)) for sector, counter in counter.items()], \n",
    "                                    key = lambda x: (x[1], companyBySector.loc[x[0], 'Count'], x[0]), reverse=True)))\n",
    "    \n",
    "    # NEW COLUMN 2B: company sector cardinality\n",
    "    counter_df['company sector cardinality'] = counter_df['company sector coverage (%)'].map(lambda counter: np.round(len(counter.keys()) / companyBySector.index.size, 2))\n",
    "    \n",
    "    # NEW COLUMN 2C: Action per sector (%)\n",
    "    counter_df['action per sector (%)'] = counter_df['Sector'].map(\n",
    "        lambda counter: dict(sorted([(sector, round(action_counter / numActionsBySector.loc[sector, 'actions'], 4)) for sector, action_counter in counter.items()], \n",
    "                                    key = lambda x: (x[1], companyBySector.loc[x[0], 'Count'], x[0]), reverse = True)))\n",
    "    #counter_df['action per sector (%)'] = counter_df['action per sector (%)'].map(lambda counter: ', '.join([item + f' ({np.round(count * 100, 1)} %)' for item, count in counter.items()]))\n",
    "\n",
    "    # Sort dataframe according to the counter\n",
    "    counter_df = counter_df.sort_values(by = ['count', 'company cardinality'], ascending = False)\n",
    "    counter_df = counter_df.rename(columns = {'company': 'action per company', 'Sector': 'action per sector'})\n",
    "    counter_df = counter_df.reindex(\n",
    "        columns = ['count', 'company cardinality', 'action per company', 'action per company (%)', 'company sector cardinality',  'company sector coverage (%)', 'action per sector', 'action per sector (%)'])\n",
    "    \n",
    "    # Save the dataframe\n",
    "    node_counters[col] = counter_df\n",
    "    display(counter_df)\n",
    "\n",
    "    # Grouped by sector\n",
    "    sectorCounter_df = merged_df[['Sector', 'company', col]].groupby(['Sector', col]).agg(Counter)\n",
    "    sectorCounter_df['count'] = sectorCounter_df['company'].map(Counter.total)\n",
    "    \n",
    "    if col == 'action':\n",
    "        sectorCounter_df.index = pd.MultiIndex.from_tuples(\n",
    "            tuples = [(sector, action.split(':')[0].strip().capitalize(), action) for sector, action in sectorCounter_df.index], \n",
    "            names = ['Sector', 'category', 'action'])\n",
    "    \n",
    "    # Visual improvements\n",
    "    sectorCounter_df['company'] = sectorCounter_df['company'].map(lambda counter: dict(sorted(counter.items(), key=lambda x: x[1], reverse=True)))\n",
    "    sectorCounter_df['idk'] = sectorCounter_df.index.get_level_values(0)\n",
    "    sectorCounter_df = sectorCounter_df[['idk', 'count', 'company']].rename(columns = {'company':'companies'}).sort_values(by = ['idk', 'count'], ascending = [True, False]).drop(columns = ['idk'])\n",
    "\n",
    "    node_counters[col + 'bySector'] = sectorCounter_df\n",
    "    \n",
    "    display(sectorCounter_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy, pearsonr\n",
    "def compute_entropy(labels, base = None):\n",
    "  _, counts  = np.unique(labels, return_counts = True)\n",
    "  probs = counts / counts.sum()  \n",
    "  \n",
    "  entropy_value = entropy(probs, base = base)\n",
    "  print(\"Entropy:\", entropy_value)\n",
    "  print(\"Entropy:\",  entropy(labels, base = base))\n",
    "  return entropy_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category - Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_entropy_df = merged_df[['category', 'predicate', 'company']].groupby('category').agg(list)\n",
    "action_entropy_df['entropy'] = action_entropy_df['predicate'].map(lambda predicates: [pred.lower() for pred in predicates]).apply(lambda predicates: compute_entropy(predicates))\n",
    "\n",
    "display()\n",
    "\n",
    "action_entropy_df['predicate'] = action_entropy_df['predicate'].map(Counter)\\\n",
    "    .map(lambda counter: {item: count / np.sum(list(counter.values())) for item, count in counter.items()})\\\n",
    "        .map(lambda counter: dict(sorted(counter.items(), key=lambda item: item[1], reverse=True)))\n",
    "\n",
    "action_entropy_df['num_predicates'] = action_entropy_df['predicate'].map(lambda counter: len(counter.keys()))\n",
    "action_entropy_df['company'] = action_entropy_df['company'].map(lambda companies: len(set(companies)) /  company_info.index.size)\n",
    "\n",
    "action_entropy_df['predicate'] = action_entropy_df['predicate'].map(lambda counter: ', '.join([item + f' ({np.round(count * 100, 1)} %)' for item, count in counter.items()]))\n",
    "\n",
    "action_entropy_df['normalized_entropy'] = (action_entropy_df['entropy'] - action_entropy_df['entropy'].min()) / (action_entropy_df['entropy'].max() - action_entropy_df['entropy'].min())\n",
    "\n",
    "\n",
    "entropyCompanies_corr = pearsonr(action_entropy_df['company'], action_entropy_df['entropy'])\n",
    "print(\"[CORRELATION]: entropy-companies\", round(entropyCompanies_corr[0], 2))\n",
    "\n",
    "entropyCompanies_corr = pearsonr(action_entropy_df['company'], action_entropy_df['normalized_entropy'])\n",
    "print(\"[CORRELATION]: normalised entropy-companies\", round(entropyCompanies_corr[0], 2))\n",
    "\n",
    "action_entropy_df = action_entropy_df[['entropy','company','num_predicates' ,'predicate']].sort_values(['entropy', 'company'], ascending=False).round(2)\n",
    "display(action_entropy_df)\n",
    "\n",
    "node_counters['action_entropy'] = action_entropy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category - Predicate by sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_entropybySector_df = merged_df[['Sector', 'category', 'predicate']]\n",
    "action_entropybySector_df = action_entropybySector_df.groupby(['Sector', 'category']).agg(list) \n",
    "action_entropybySector_df['entropy'] = action_entropybySector_df['predicate'].map(lambda predicates: [pred.lower() for pred in predicates]).apply(lambda predicates: compute_entropy(predicates))\n",
    "\n",
    "action_entropybySector_df = action_entropybySector_df.reset_index()[['Sector', 'entropy']].groupby('Sector').agg({'entropy': ['median','mean','std']})\n",
    "action_entropybySector_df.columns = [col[1] + '_' + col[0] for col in action_entropybySector_df.columns]\n",
    "\n",
    "action_entropybySector_df = action_entropybySector_df.sort_values(by = ['median_entropy', 'mean_entropy'], ascending=False) # type: ignore\n",
    "\n",
    "node_counters['action_sectorEntropy']  = action_entropybySector_df\n",
    "display(action_entropybySector_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = path.join('..', 'outputs', 'graph_analyses')\n",
    "\n",
    "for method, counter_df in node_counters.copy().items():\n",
    "    if 'by' not in method:\n",
    "        file_path = path.join(folder_path, 'sector_stats_' + method + ('_clustered' if clustered_triples else '') + '.json')\n",
    "        counter_df.to_json(file_path, orient = 'index', indent = 4) # orient = 'index', \n",
    "        \n",
    "        print('METHOD', method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringy_func = lambda items: ', '.join([ f'{name} ({count})' for name, count in items.items()])\n",
    "with pd.ExcelWriter(path.join(folder_path, 'sector_stats' + ('_clustered' if clustered_triples else '') + '.xlsx')) as writer:\n",
    "    \n",
    "    # Aggregated stats\n",
    "    for sheet_name, counter_df in node_counters.items():\n",
    "        \n",
    "        to_save = counter_df.copy()\n",
    "        \n",
    "        # Visual improvements: strinfy dictionarioes\n",
    "        cols_to_stringify = ['action per company', 'action per sector', 'action per company (%)', 'action per sector (%)', 'company sector coverage (%)']\n",
    "        for col in cols_to_stringify:\n",
    "            if col in counter_df.columns:\n",
    "                if '%' in col:\n",
    "                    to_save[col] = to_save[col].map(lambda items: ', '.join([ f'{name} ({np.round(count*100, 1)}%)' for name, count in items.items()]))\n",
    "                else:\n",
    "                    to_save[col] = to_save[col].map(stringy_func)\n",
    "        \n",
    "        # Visual improvements: uppercase column names\n",
    "        to_save.columns = [col.upper() for col in to_save.columns]\n",
    "        \n",
    "        # Save to excel\n",
    "        to_save.to_excel(writer, sheet_name = sheet_name)\n",
    "        \n",
    "    # Save info\n",
    "    companyBySector.to_excel(writer, sheet_name = 'info')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
